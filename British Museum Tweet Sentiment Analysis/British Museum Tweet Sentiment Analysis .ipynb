{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a513717e-5bd2-4578-8d92-6e01f71fdcfb",
   "metadata": {},
   "source": [
    "# British Museum Tweet Sentiment Analysis (BERT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c921ce8c-3bdc-4794-a62c-d5f164cb4185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Intel(R) Extension for Scikit-learn* enabled (https://github.com/intel/scikit-learn-intelex)\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch \n",
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, BertModel\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "\n",
    "from sklearnex import patch_sklearn\n",
    "patch_sklearn()\n",
    "\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import warnings \n",
    "warnings.filterwarnings(\"ignore\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0ff4e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(r\"C:\\Users\\Al-Amin\\Desktop\\Data_Analyst_Projects\\Python\\Sentitment Analysis (Bert)\\Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b46bd6-b2ff-400f-8179-0ecae3d06c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"smile-annotations-final.csv\", \n",
    "                 names = ['id', 'text', 'category'])\n",
    "df.set_index('id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ba16c64-ddd5-4438-ad07-b74806144d57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611857364396965889</th>\n",
       "      <td>@aandraous @britishmuseum @AndrewsAntonio Merc...</td>\n",
       "      <td>nocode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614484565059596288</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614746522043973632</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614877582664835073</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611932373039644672</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text category\n",
       "id                                                                            \n",
       "611857364396965889  @aandraous @britishmuseum @AndrewsAntonio Merc...   nocode\n",
       "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...    happy\n",
       "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...    happy\n",
       "614877582664835073  @Sofabsports thank you for following me back. ...    happy\n",
       "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...    happy"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adf69379-5566-44e0-ba15-a9fcf5439909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dorian Gray with Rainbow Scarf #LoveWins (from @britishmuseum http://t.co/Q4XSwL0esu) http://t.co/h0evbTBWRq'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "900a60a8-d1b7-419e-940c-8a87c36d6b85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "nocode               1572\n",
       "happy                1137\n",
       "not-relevant          214\n",
       "angry                  57\n",
       "surprise               35\n",
       "sad                    32\n",
       "happy|surprise         11\n",
       "happy|sad               9\n",
       "disgust|angry           7\n",
       "disgust                 6\n",
       "sad|disgust             2\n",
       "sad|angry               2\n",
       "sad|disgust|angry       1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a31623d6-db89-43ff-8524-44dbab423f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing categories with multiple emotions\n",
    "df = df[~df.category.str.contains('\\|')]\n",
    "\n",
    "# Removing nocode from categories\n",
    "df = df[df.category != 'nocode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02d166ba-5fc2-4118-a652-36ef29fac30b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "happy           1137\n",
       "not-relevant     214\n",
       "angry             57\n",
       "surprise          35\n",
       "sad               32\n",
       "disgust            6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b9f829c-1c6a-466c-86c6-06bd619918d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'happy': 0,\n",
       " 'not-relevant': 1,\n",
       " 'angry': 2,\n",
       " 'disgust': 3,\n",
       " 'sad': 4,\n",
       " 'surprise': 5}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "possible_labels = df.category.unique()\n",
    "label_dict = {}\n",
    "for index, possible_label in enumerate(possible_labels):\n",
    "    label_dict[possible_label] = index\n",
    "\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7d6c5d3a-6f1d-4b05-9f3e-8c12d9b53468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>614484565059596288</th>\n",
       "      <td>Dorian Gray with Rainbow Scarf #LoveWins (from...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614746522043973632</th>\n",
       "      <td>@SelectShowcase @Tate_StIves ... Replace with ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614877582664835073</th>\n",
       "      <td>@Sofabsports thank you for following me back. ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611932373039644672</th>\n",
       "      <td>@britishmuseum @TudorHistory What a beautiful ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611570404268883969</th>\n",
       "      <td>@NationalGallery @ThePoldarkian I have always ...</td>\n",
       "      <td>happy</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                 text  \\\n",
       "id                                                                      \n",
       "614484565059596288  Dorian Gray with Rainbow Scarf #LoveWins (from...   \n",
       "614746522043973632  @SelectShowcase @Tate_StIves ... Replace with ...   \n",
       "614877582664835073  @Sofabsports thank you for following me back. ...   \n",
       "611932373039644672  @britishmuseum @TudorHistory What a beautiful ...   \n",
       "611570404268883969  @NationalGallery @ThePoldarkian I have always ...   \n",
       "\n",
       "                   category  label  \n",
       "id                                  \n",
       "614484565059596288    happy      0  \n",
       "614746522043973632    happy      0  \n",
       "614877582664835073    happy      0  \n",
       "611932373039644672    happy      0  \n",
       "611570404268883969    happy      0  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.category.replace(label_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8b9fa8e1-6abc-4fbd-881d-72ceec24e9a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category      label\n",
       "angry         2          57\n",
       "disgust       3           6\n",
       "happy         0        1137\n",
       "not-relevant  1         214\n",
       "sad           4          32\n",
       "surprise      5          35\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('category')['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dded04f-c4a4-4910-ad1a-21e266b8ce66",
   "metadata": {},
   "source": [
    "There is clearly an imbalance in the data in terms of the emotions associated with the text. We would need to take this into consideration when forming our train/test split. Essentially, we will stratify our samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c11fe514-7d6d-47c4-8a1c-34ef1dfaee5a",
   "metadata": {},
   "source": [
    "### Training/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1f51a42f-9761-4c23-a0fe-570f517c88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.index\n",
    "y = df.label.values\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, stratify =y, test_size = 0.15, random_state = 17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1fe89b04-6c67-49c9-ae8c-4afc04f5344f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "      <th>data_type</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">angry</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>train</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">disgust</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">3</th>\n",
       "      <th>train</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">happy</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>train</th>\n",
       "      <td>966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">not-relevant</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>train</th>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">sad</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">4</th>\n",
       "      <th>train</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">surprise</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">5</th>\n",
       "      <th>train</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>val</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text\n",
       "category     label data_type      \n",
       "angry        2     train        48\n",
       "                   val           9\n",
       "disgust      3     train         5\n",
       "                   val           1\n",
       "happy        0     train       966\n",
       "                   val         171\n",
       "not-relevant 1     train       182\n",
       "                   val          32\n",
       "sad          4     train        27\n",
       "                   val           5\n",
       "surprise     5     train        30\n",
       "                   val           5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking how the data will be split\n",
    "\n",
    "df['data_type'] = 'not_set'\n",
    "\n",
    "df.loc[X_train, 'data_type'] = 'train'\n",
    "df.loc[X_val, 'data_type'] = 'val'\n",
    "\n",
    "df.groupby(['category', 'label', 'data_type']).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a755e6c-3690-4ca7-83de-b719775e09fb",
   "metadata": {},
   "source": [
    "#### Encoding text into numerical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20b0b466-3bca-4e15-8e8a-70f7df708d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True, clean_up_tokenization_spaces = True)\n",
    "\n",
    "encoded_train = tokenizer.batch_encode_plus(df[df.data_type == 'train'].text.values, \n",
    "                                            add_special_tokens = True, \n",
    "                                            return_attention_mask = True, \n",
    "                                            padding = 'max_length',\n",
    "                                            truncation = True,\n",
    "                                            max_length  = 256, \n",
    "                                            return_tensors = 'pt')\n",
    "\n",
    "input_ids_train = encoded_train['input_ids']\n",
    "attention_masks_train = encoded_train['attention_mask']\n",
    "label_train = torch.tensor(df[df.data_type == 'train'].label.values)\n",
    "\n",
    "train_data = TensorDataset(input_ids_train, attention_masks_train, label_train)\n",
    "\n",
    "encoded_val = tokenizer.batch_encode_plus(df[df.data_type == 'val'].text.values, \n",
    "                                            add_special_tokens = True, \n",
    "                                            return_attention_mask = True, \n",
    "                                            padding = 'max_length',\n",
    "                                            truncation = True,\n",
    "                                            max_length  = 256, \n",
    "                                            return_tensors = 'pt')\n",
    "\n",
    "input_ids_val = encoded_val['input_ids']\n",
    "attention_masks_val = encoded_val['attention_mask']\n",
    "label_val = torch.tensor(df[df.data_type == 'val'].label.values)\n",
    "\n",
    "val_data = TensorDataset(input_ids_val, attention_masks_val, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "04b6bf65-3212-4588-8626-e0771ab1f3a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1258, 223)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data),len(val_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33f249d0-ba7f-40d4-8fd1-3a34bba4d09a",
   "metadata": {},
   "source": [
    "### Setting up BERT Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1cc0b081-fdc8-4ae4-9f89-db8595f98091",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', \n",
    "                                      num_labels = len(label_dict), \n",
    "                                      output_attentions = False, \n",
    "                                      output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581f6f76-e12e-4323-8f54-1b16d5606ef6",
   "metadata": {},
   "source": [
    "### Creating Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b3efb87b-c404-4e79-a461-5b695dea7017",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "dataloader_train = DataLoader(train_data, sampler = RandomSampler(train_data), batch_size = batch_size)\n",
    "\n",
    "dataloader_val = DataLoader(val_data, sampler = RandomSampler(val_data), batch_size = 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9ae9c0-3386-49de-9ab7-58cf2084bf07",
   "metadata": {},
   "source": [
    "### Setting up Optimizer and Scheduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ca476e00-b51f-4f2c-9476-d003df8170c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr = 1e-5, eps = 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3f879c80-e9cb-4887-839d-9383a5d173c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, \n",
    "                                            num_training_steps = len(dataloader_train)*epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e63b208-6292-402d-a901-1f6f22235dfe",
   "metadata": {},
   "source": [
    "### Defining our Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "63aac24b-f9a0-4966-9dd6-93e1f56efb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_score_func(preds, labels):\n",
    "    preds_flat = np.argmax(preds, axis =1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return f1_score(labels_flat, preds_flat, average = 'weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12ced768-d64c-4234-a124-1995700b3cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_per_class(preds, labels):  \n",
    "    label_dict_inverse = {v: k for k, v in label_dict.items()}\n",
    "    preds_flat = np.argmax(preds, axis =1).flatten()\n",
    "    labels_flat = labels.flatten()   \n",
    "\n",
    "    for label in np.unique(labels_flat):\n",
    "        y_preds = preds_flat[labels_flat == label]\n",
    "        y_true = labels_flat[labels_flat == label]\n",
    "        print(f'Class: {label_dict_inverse[label]}')\n",
    "        print(f'Accuracy: {len(y_preds[y_preds == label])}/{len(y_true)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22d38a6-6303-4000-9e96-a180dc7492a4",
   "metadata": {},
   "source": [
    "### Creating our Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "21351734-8c0a-4cbc-837c-ae6e4058e16e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2890599d8d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random \n",
    "\n",
    "seed_val = 17\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "001fba55-0c79-47e3-92a6-797a7793f887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6faa2532-9438-421a-b40b-8b382af5f11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(dataloader_val):\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    loss_val_total = 0\n",
    "    predictions, true_vals = [], []\n",
    "    \n",
    "    for batch in tqdm(dataloader_val):\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids':      batch[0],\n",
    "                  'attention_mask': batch[1],\n",
    "                  'labels':         batch[2],\n",
    "                 }\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        loss = outputs[0]\n",
    "        logits = outputs[1]\n",
    "        loss_val_total += loss.item()\n",
    "\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = inputs['labels'].cpu().numpy()\n",
    "        predictions.append(logits)\n",
    "        true_vals.append(label_ids)\n",
    "    \n",
    "    loss_val_avg = loss_val_total/len(dataloader_val) \n",
    "    \n",
    "    predictions = np.concatenate(predictions, axis=0)\n",
    "    true_vals = np.concatenate(true_vals, axis=0)\n",
    "            \n",
    "    return loss_val_avg, predictions, true_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32dff72d-7ac1-4027-97bd-f011c0baea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "model_dir = 'torch_models'\n",
    "os.makedirs(model_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6f8d48c-f644-42a5-b4c1-24834042c77f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccbebc903e8547d39fae7a7227bd2bdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173abde1b7134080ae0d91cdc016247c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch 1:   0%|          | 0/315 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch {epoch}\n",
      "Training loss: {loss_train_avg}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "edb95a3f67c643feb26d392e09fb5432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.7401401443140847\n",
      "F1 Score (Weighted) : 0.7043271626231267\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, epochs+1)):\n",
    "    model.train()\n",
    "    loss_train_total = 0\n",
    "    progress_bar = tqdm(dataloader_train, desc = 'Epoch {:1d}'.format(epoch), leave = False, disable = False)\n",
    "    \n",
    "    for batch in progress_bar:\n",
    "        \n",
    "        model.zero_grad()\n",
    "        \n",
    "        batch = tuple(b.to(device) for b in batch)\n",
    "        \n",
    "        inputs = {'input_ids' : batch[0], \n",
    "                  'attention_mask' : batch[1], \n",
    "                  'labels' : batch[2]}\n",
    "        \n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "        loss = outputs[0]\n",
    "        loss_train_total += loss.item()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        progress_bar.set_postfix({'training_loss' : '{:.3f}'.format(loss.item()/len(batch))})\n",
    "\n",
    "    model_save_path = os.path.join(model_dir, f'Bert_ft_epoch{epoch}.model')\n",
    "    torch.save(model.state_dict(), model_save_path)\n",
    "    tqdm.write('\\nEpoch {epoch}')\n",
    "    loss_train_avg = loss_train_total/len(dataloader_train)\n",
    "    tqdm.write('Training loss: {loss_train_avg}')\n",
    "\n",
    "    val_loss, predictions, true_vals = evaluate(dataloader_val)\n",
    "    val_f1 = f1_score_func(predictions, true_vals)\n",
    "    tqdm.write(f'Validation Loss: {val_loss}')\n",
    "    tqdm.write(f'F1 Score (Weighted) : {val_f1}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc8bb6d7-f8fa-4d2c-a096-0aa9efb42fa6",
   "metadata": {},
   "source": [
    "### Loading and evaluating our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2d4aa0a0-d919-430e-8ca3-5c11d9061098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r\"torch_models\\Bert_ft_epoch1.model\"\n",
    "model.load_state_dict(torch.load(model_path, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2d037c37-868a-4ea2-835f-026eab8e8776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a75a3513a84a809e41e8facb67f473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_, preicitions, true_vals = evaluate(dataloader_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ebd04a9f-b285-40c2-adb9-521982303aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class: happy\n",
      "Accuracy: 168/171\n",
      "\n",
      "Class: not-relevant\n",
      "Accuracy: 1/32\n",
      "\n",
      "Class: angry\n",
      "Accuracy: 0/9\n",
      "\n",
      "Class: disgust\n",
      "Accuracy: 0/1\n",
      "\n",
      "Class: sad\n",
      "Accuracy: 0/5\n",
      "\n",
      "Class: surprise\n",
      "Accuracy: 0/5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "accuracy_per_class(predictions, true_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721b0345-88b0-49da-b127-357e154301de",
   "metadata": {},
   "source": [
    "Ideally we would want to increase the batch size and the number of epochs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
